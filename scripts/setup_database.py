#!/usr/bin/env python3
"""
í•œêµ­ì–´ ì“°ê¸° ìë™ ì±„ì  ì‹œìŠ¤í…œ - DB ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
"""

import psycopg2
import json
from openai import OpenAI
import os
from pathlib import Path

# OpenAI API ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# PostgreSQL ì—°ê²° ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", "5432"),
    "database": os.getenv("DB_NAME", "korean_grading"),
    "user": os.getenv("DB_USER", "postgres"),
    "password": os.getenv("DB_PASSWORD", "")
}


def get_embedding(text: str, model="text-embedding-3-small") -> list:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    text = text.replace("\n", " ")
    response = client.embeddings.create(input=[text], model=model)
    return response.data[0].embedding


def init_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì‹¤í–‰
    schema_path = Path(__file__).parent.parent / "database" / "schema.sql"
    with open(schema_path, 'r', encoding='utf-8') as f:
        schema_sql = f.read()

    cur.execute(schema_sql)
    conn.commit()

    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")

    cur.close()
    conn.close()


def load_grading_criteria():
    """ì±„ì  ê¸°ì¤€ ë°ì´í„°ë¥¼ DBì— ë¡œë“œ"""
    print("\nğŸ“ ì±„ì  ê¸°ì¤€ ë¡œë”© ì¤‘...")

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # JSON íŒŒì¼ ì½ê¸°
    criteria_path = Path(__file__).parent.parent / "grading-criteria" / "lesson_2A_1.json"
    with open(criteria_path, 'r', encoding='utf-8') as f:
        criteria_data = json.load(f)

    lesson = criteria_data["lesson"]

    # 1. ê³¼ì œ ì •ë³´ ì €ì¥
    cur.execute("""
        INSERT INTO assignments (assignment_name, lesson_number, required_sentences)
        VALUES (%s, %s, %s)
        RETURNING assignment_id
    """, (
        criteria_data["assignment"]["title"],
        lesson,
        criteria_data["assignment"]["required_sentences"]
    ))
    assignment_id = cur.fetchone()[0]
    print(f"âœ… ê³¼ì œ ì •ë³´ ì €ì¥ ì™„ë£Œ (ID: {assignment_id})")

    # 2. ì±„ì  ê¸°ì¤€ ì €ì¥ (RAGìš©)
    for category, details in criteria_data["scoring_criteria"].items():
        criteria_text = f"{details['name']}: {details.get('description', '')}"

        # ì„ë² ë”© ìƒì„±
        embedding = get_embedding(criteria_text)

        cur.execute("""
            INSERT INTO grading_criteria
            (lesson_number, category, criteria_name, criteria_description, scoring_rule, examples, embedding)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """, (
            lesson,
            category,
            details['name'],
            details.get('description', ''),
            json.dumps(details.get('rules', []), ensure_ascii=False),
            json.dumps(details, ensure_ascii=False),
            embedding
        ))

    conn.commit()
    print(f"âœ… ì±„ì  ê¸°ì¤€ {len(criteria_data['scoring_criteria'])}ê°œ ì €ì¥ ì™„ë£Œ")

    # 3. ë¬¸ë²• ê·œì¹™ ì €ì¥ (RAGìš©)
    for grammar in criteria_data["grammar_rules"]:
        grammar_text = f"{grammar['name']}: {grammar['usage']}"

        # ì„ë² ë”© ìƒì„±
        embedding = get_embedding(grammar_text)

        # detection_patternsë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        detection_pattern = "|".join(grammar["detection_patterns"])

        cur.execute("""
            INSERT INTO grammar_rules
            (lesson_number, grammar_name, grammar_form, usage_description,
             score_weight, detection_pattern, examples, embedding)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            lesson,
            grammar['name'],
            json.dumps(grammar['forms'], ensure_ascii=False),
            grammar['usage'],
            grammar['score'],
            detection_pattern,
            json.dumps(grammar['examples'], ensure_ascii=False),
            embedding
        ))

    conn.commit()
    print(f"âœ… ë¬¸ë²• ê·œì¹™ {len(criteria_data['grammar_rules'])}ê°œ ì €ì¥ ì™„ë£Œ")

    cur.close()
    conn.close()


def create_sample_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    print("\nğŸ§ª ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # ìƒ˜í”Œ í•™ìƒ ìƒì„±
    sample_students = [
        ("20240001", "ê¹€ë¯¼ì¤€"),
        ("20240002", "ì´ì„œì—°"),
        ("20240003", "ë°•ì§€í˜¸")
    ]

    for student_number, student_name in sample_students:
        cur.execute("""
            INSERT INTO students (student_number, student_name)
            VALUES (%s, %s)
            ON CONFLICT (student_number) DO NOTHING
        """, (student_number, student_name))

    conn.commit()
    print(f"âœ… ìƒ˜í”Œ í•™ìƒ {len(sample_students)}ëª… ìƒì„± ì™„ë£Œ")

    cur.close()
    conn.close()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("í•œêµ­ì–´ ì“°ê¸° ìë™ ì±„ì  ì‹œìŠ¤í…œ - ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")
    print("=" * 60)

    try:
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        init_database()

        # 2. ì±„ì  ê¸°ì¤€ ë¡œë“œ
        load_grading_criteria()

        # 3. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        create_sample_data()

        print("\n" + "=" * 60)
        print("âœ¨ ì´ˆê¸°í™” ì™„ë£Œ!")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
